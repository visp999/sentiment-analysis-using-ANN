{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bd2ca7ac9c81bec106873a05bcd41673070c5cef006a5fce48615174ff2fdaa3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Importing required libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "source": [
    "Loading the data and assigning column names"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>id</th>\n      <th>date</th>\n      <th>flag</th>\n      <th>user</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = pd.read_csv('td.csv',encoding='ISO-8859-1', names=['target','id','date','flag','user','text'])\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "Defining the sample size and train, test sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = int(len(df)*0.1)\n",
    "sampleDf = df.sample(sample_size, random_state=23)\n",
    "x = sampleDf.text.values\n",
    "y = sampleDf.target.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "source": [
    "Tokenizing train data, converting train and test data to indices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "source": [
    "Determining the maximum length of sequence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max len: 118\n"
     ]
    }
   ],
   "source": [
    "lens_train = [len(i) for i in X_train]\n",
    "lens_test = [len(i) for i in X_test]\n",
    "lens = lens_train + lens_test\n",
    "\n",
    "maxlen = np.max(lens)\n",
    "\n",
    "print('Max len:', maxlen)"
   ]
  },
  {
   "source": [
    "Padding the sequences upto the maximum length"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "source": [
    "Encoding labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y_test = encoder.transform(y_test)\n",
    "encoded_Y_train = encoder.transform(y_train)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 118, 100)          11789900  \n_________________________________________________________________\ndropout (Dropout)            (None, 118, 100)          0         \n_________________________________________________________________\nglobal_max_pooling1d (Global (None, 100)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense (Dense)                (None, 50)                5050      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 50)                2550      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 102       \n=================================================================\nTotal params: 11,797,602\nTrainable params: 11,797,602\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100  \n",
    "\n",
    "model = Sequential()  # initiates the model\n",
    "model.add(layers.Embedding(input_dim=vocab_size,  # adds the first [input] layer which will be our tokenized tweets\n",
    "                          output_dim=embedding_dim,  # the embedding of that tweet, essentially inputs output\n",
    "                          input_length=maxlen))  # size of the input layer determined by maxlen calculated before\n",
    "model.add(layers.Dropout(0.2))  # dorpouts are added to help with overtraining, essentially \"turns off\" said amount of neurons before giving information to the next layer\n",
    "model.add(layers.GlobalMaxPool1D())  \n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(50, activation='relu'))  # additional hidden layer\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(2, activation='softmax'))  # prediction layer, 2 is the number of classes we have\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "Fitting the model onto train data and running it to find the accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "1000/1000 [==============================] - 279s 277ms/step - loss: 0.5746 - accuracy: 0.6826 - val_loss: 0.4515 - val_accuracy: 0.7889\n",
      "Epoch 2/3\n",
      "1000/1000 [==============================] - 263s 263ms/step - loss: 0.4018 - accuracy: 0.8181 - val_loss: 0.4439 - val_accuracy: 0.7904\n",
      "Epoch 3/3\n",
      "1000/1000 [==============================] - 273s 273ms/step - loss: 0.3285 - accuracy: 0.8551 - val_loss: 0.4664 - val_accuracy: 0.7853\n",
      "Training Accuracy: 0.9118\n",
      "Testing Accuracy:  0.7853\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, dummy_y_train,\n",
    "                    epochs=3,  # times model will run through the data\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, dummy_y_test),\n",
    "                    batch_size=128)  # data is set to batches we are sent to the model to predict, imagine each batc as a step in which model tries to predict the class and then checks the right answer and corrects it's weights with backpropogation\n",
    "loss, accuracy = model.evaluate(X_train, dummy_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, dummy_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "source": [
    "Testing the model with a tweet to demonstrate sentiment prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tweet is positive\n"
     ]
    }
   ],
   "source": [
    " tweet = 'Great place to visit !'\n",
    "vectTweet = tokenizer.texts_to_sequences(np.array([tweet]))  # vectorizes the tweet using our vectorizer\n",
    "vectTweet = pad_sequences(vectTweet, padding='post', maxlen=maxlen)  # adds padding\n",
    "\n",
    "prediction = model.predict(vectTweet)  # predicts class of the tweet\n",
    "print('Tweet is', 'positive' if encoder.classes_[np.argmax(prediction)]==4 else 'negative')"
   ]
  }
 ]
}